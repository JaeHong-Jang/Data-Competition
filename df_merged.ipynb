{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2949a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc9b915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['01_SSP1_데이터.csv', '02_SSP3_데이터.csv', '03_SSP5_데이터.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efdeb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 3개의 데이터프레임이 성공적으로 처리 및 태깅되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로와 해당 시나리오 이름을 매핑하는 딕셔너리를 생성합니다.\n",
    "# 이 구조는 새로운 시나리오(예: SSP2, SSP4)가 추가될 때 코드 수정 없이\n",
    "# 딕셔너리에 항목만 추가하면 되므로 확장성이 매우 뛰어납니다.\n",
    "scenario_mapping = {\n",
    "    '01_SSP1_데이터.csv': 'SSP1',\n",
    "    '02_SSP3_데이터.csv': 'SSP3',\n",
    "    '03_SSP5_데이터.csv': 'SSP5'\n",
    "}\n",
    "\n",
    "# 개별적으로 처리된 데이터프레임을 저장할 빈 리스트를 초기화합니다.\n",
    "list_of_dataframes = []\n",
    "\n",
    "# 딕셔너리를 순회하며 각 파일을 처리합니다.\n",
    "for file_path, scenario_name in scenario_mapping.items():\n",
    "    # CSV 파일을 데이터프레임으로 읽어옵니다.\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 'Scenario'라는 새로운 열을 추가하고, 해당 시나리오 이름으로 값을 채웁니다.\n",
    "    # 이 작업은 데이터가 다른 출처와 섞이기 전에 수행되어 출처의 무결성을 보장합니다.\n",
    "    df['Scenario'] = scenario_name\n",
    "    \n",
    "    # 처리된 데이터프레임을 리스트에 추가합니다.\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "print(f\"총 {len(list_of_dataframes)}개의 데이터프레임이 성공적으로 처리 및 태깅되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8bc09aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임 병합 완료.\n",
      "최종 데이터셋의 형태(행, 열): (405, 26)\n"
     ]
    }
   ],
   "source": [
    "# pd.concat 함수를 사용하여 리스트에 있는 모든 데이터프레임을 수직으로 결합합니다.\n",
    "# 이 함수는 스키마가 동일한 데이터프레임들을 효율적으로 쌓아줍니다.\n",
    "merged_df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "\n",
    "# ignore_index=True 인자는 매우 중요합니다.\n",
    "# 이 옵션은 기존의 개별 인덱스를 무시하고, 0부터 시작하는 연속적인 새 인덱스를\n",
    "# 최종 데이터프레임에 부여합니다. 이는 데이터 슬라이싱, 필터링 등\n",
    "# 후속 분석 작업의 일관성과 편의성을 위해 필수적입니다.\n",
    "\n",
    "print(\"데이터프레임 병합 완료.\")\n",
    "print(\"최종 데이터셋의 형태(행, 열):\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fab84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예상 행 수: 405, 실제 행 수: 405\n",
      "예상 열 수: 26, 실제 열 수: 26\n",
      "차원 검증 통과: 데이터의 손실이나 불필요한 추가 없이 병합되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 원본 파일들의 총 행 수를 계산하여 예상되는 최종 행 수를 구합니다.\n",
    "expected_rows = 0\n",
    "for df in list_of_dataframes:\n",
    "    expected_rows += len(df)\n",
    "\n",
    "# 최종 병합된 데이터프레임의 실제 차원을 확인합니다.\n",
    "actual_rows, actual_cols = merged_df.shape\n",
    "\n",
    "# 예상되는 열의 수는 원본 25개 + 새로 추가된 'Scenario' 열 1개 = 26개입니다.\n",
    "expected_cols = 26\n",
    "\n",
    "# 검증 결과를 출력합니다.\n",
    "print(f\"예상 행 수: {expected_rows}, 실제 행 수: {actual_rows}\")\n",
    "print(f\"예상 열 수: {expected_cols}, 실제 열 수: {actual_cols}\")\n",
    "\n",
    "# 자동 검증 로직\n",
    "if actual_rows == expected_rows and actual_cols == expected_cols:\n",
    "    print(\"차원 검증 통과: 데이터의 손실이나 불필요한 추가 없이 병합되었습니다.\")\n",
    "else:\n",
    "    print(\"차원 검증 실패: 데이터 처리 과정에 오류가 있을 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7ba7555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 데이터 불러오기 및 병합 시작 ---\n",
      "데이터프레임 병합 완료.\n",
      "최종 데이터셋의 형태(행, 열): (405, 26)\n",
      "\n",
      "--- [디버깅] 병합 후 실제 컬럼명 확인 ---\n",
      "Index(['month', 'CO2ppm', 'Temp', 'Humid', 'VPD', 'Chl_a', 'Chl_b', 'TChl',\n",
      "       'Car', 'Chl_a_b', 'TCh-Car', 'ABS-RC', 'Dio-RC', 'Tro-RC', 'Eto-RC',\n",
      "       'PI_abs', 'DF_abs', 'SFI_abs', 'Fv-Fm', 'Leaf_ExtractionYield',\n",
      "       'Root_ExtractionYield', 'Leaf_TPC', 'Root_TPC', 'Leaf_TFC', 'Root_TFC',\n",
      "       'scenario'],\n",
      "      dtype='object')\n",
      "\n",
      "--- [디버깅] 병합 후 데이터 상위 5개 확인 ---\n",
      "   month      CO2ppm       Temp      Humid       VPD  Chl_a  Chl_b   TChl  \\\n",
      "0      5  381.681033  16.918639  83.130786  1.532512   8.79   2.22  11.00   \n",
      "1      5  374.463441  16.922124  83.096722  1.532868   8.99   2.56  11.55   \n",
      "2      5  371.850683  16.930256  82.488003  1.534584   9.66   2.44  12.10   \n",
      "3      5  400.475202  16.921511  82.081632  1.534512   9.33   2.45  11.79   \n",
      "4      5  381.360788  16.921323  83.888666  1.531475  10.53   2.58  13.11   \n",
      "\n",
      "    Car  Chl_a_b  ...  DF_abs  SFI_abs  Fv-Fm  Leaf_ExtractionYield  \\\n",
      "0  2.97     3.97  ...   0.328    0.215  0.830                  19.0   \n",
      "1  3.09     3.52  ...   0.287    0.199  0.826                  20.1   \n",
      "2  3.11     3.96  ...   0.384    0.229  0.828                  20.7   \n",
      "3  3.13     3.80  ...   0.503    0.282  0.839                  19.0   \n",
      "4  3.37     4.08  ...   0.304    0.203  0.832                  20.1   \n",
      "\n",
      "   Root_ExtractionYield  Leaf_TPC  Root_TPC  Leaf_TFC  Root_TFC  scenario  \n",
      "0                  18.9     7.476     6.270     5.217     0.861      SSP1  \n",
      "1                  19.6     7.369     6.396     5.257     0.836      SSP1  \n",
      "2                  20.4     7.369     6.396     5.242     0.841      SSP1  \n",
      "3                  18.9     7.476     6.270     5.217     0.861      SSP1  \n",
      "4                  19.6     7.369     6.396     5.257     0.836      SSP1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- 데이터 병합 검증 시작 ---\n",
      "\n",
      "'scenario' 열의 값 분포:\n",
      "scenario\n",
      "SSP1    135\n",
      "SSP3    135\n",
      "SSP5    135\n",
      "Name: count, dtype: int64\n",
      "✅ [SSP1] 검증 통과: 원본(135 행) == 병합 후(135 행)\n",
      "✅ [SSP3] 검증 통과: 원본(135 행) == 병합 후(135 행)\n",
      "✅ [SSP5] 검증 통과: 원본(135 행) == 병합 후(135 행)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. 파일 준비 ---\n",
    "file_paths = ['01_SSP1_데이터.csv', '02_SSP3_데이터.csv', '03_SSP5_데이터.csv']\n",
    "list_of_dataframes = []\n",
    "\n",
    "print(\"--- 데이터 불러오기 및 병합 시작 ---\")\n",
    "\n",
    "# --- 2. 반복문으로 파일 불러오기 및 'scenario' 컬럼 추가 ---\n",
    "for path in file_paths:\n",
    "    # CSV 파일을 데이터프레임으로 읽어옵니다.\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # 파일명에서 시나리오 정보(예: SSP1)를 추출합니다.\n",
    "    scenario_name = os.path.basename(path).split('_')[1]\n",
    "    \n",
    "    # 'scenario'라는 새로운 컬럼을 만들고 추출한 시나리오 이름을 값으로 할당합니다.\n",
    "    # ★★★ 여기가 가장 중요! 'scenario' 컬럼이 여기서 생성됩니다. ★★★\n",
    "    df['scenario'] = scenario_name\n",
    "    \n",
    "    # 처리된 데이터프레임을 리스트에 추가합니다.\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "# --- 3. 데이터프레임 하나로 합치기 ---\n",
    "merged_df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "\n",
    "print(\"데이터프레임 병합 완료.\")\n",
    "print(\"최종 데이터셋의 형태(행, 열):\", merged_df.shape)\n",
    "\n",
    "\n",
    "# --- 4. 디버깅: 병합 후 컬럼명과 데이터 확인 (오류 원인 찾기) ---\n",
    "print(\"\\n--- [디버깅] 병합 후 실제 컬럼명 확인 ---\")\n",
    "print(merged_df.columns) # 이 출력을 통해 'scenario' 컬럼이 잘 만들어졌는지 확인!\n",
    "\n",
    "print(\"\\n--- [디버깅] 병합 후 데이터 상위 5개 확인 ---\")\n",
    "print(merged_df.head()) # 'scenario' 컬럼과 값이 잘 들어갔는지 눈으로 확인!\n",
    "\n",
    "\n",
    "# --- 5. 최종 검증 ---\n",
    "print(\"\\n--- 데이터 병합 검증 시작 ---\")\n",
    "\n",
    "# 'scenario' 열의 각 고유값과 그에 해당하는 행의 수를 계산합니다.\n",
    "# 이 코드가 제대로 실행되려면 바로 위에서 'scenario' 컬럼이 정상적으로 보여야 합니다.\n",
    "scenario_counts = merged_df['scenario'].value_counts()\n",
    "\n",
    "print(\"\\n'scenario' 열의 값 분포:\")\n",
    "print(scenario_counts)\n",
    "\n",
    "# 원본 데이터와 비교하여 검증합니다.\n",
    "for original_df, path in zip(list_of_dataframes, file_paths):\n",
    "    scenario_name = os.path.basename(path).split('_')[1]\n",
    "    original_row_count = len(original_df)\n",
    "    merged_row_count = scenario_counts[scenario_name]\n",
    "    \n",
    "    if original_row_count == merged_row_count:\n",
    "        print(f\"✅ [{scenario_name}] 검증 통과: 원본({original_row_count} 행) == 병합 후({merged_row_count} 행)\")\n",
    "    else:\n",
    "        print(f\"❌ [{scenario_name}] 검증 실패: 원본({original_row_count} 행) != 병합 후({merged_row_count} 행)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa300c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('df_merged.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
